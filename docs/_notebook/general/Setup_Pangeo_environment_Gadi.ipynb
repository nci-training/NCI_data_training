{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Setup for Pangeo Environment on Gadi\n",
    "\n",
    "\n",
    "In this notebook we will go through:\n",
    "\n",
    "- Configuring the Pangeo environment using your Gadi account\n",
    "- Submitting and monitoring multi-node Pangeo jobs to Gadi\n",
    "- Running Pangeo Jupyter notebooks in batch mode non-interactively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [Pangeo](http://pangeo.io) software ecosystem involves open source tools such as [xarray](http://xarray.pydata.org/en/stable/), [iris](https://scitools.org.uk/iris/docs/latest/), [dask](https://dask.org/), [Jupyter](https://jupyter.org/) and many other packages. \n",
    "\n",
    "This notebook provides instructions on how to use the Pangeo environment to run a multi-node parallel Jupyter notebook within the queues on Gadi and shows how to interact with it from your desktop.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuring your account on Gadi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step 1: Enabling Pangeo in your shell envorinment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To enable the Pangeo environment, you can use the following command within jobs, or within an interactive environment:\n",
    "\n",
    "```\n",
    "$ module load pangeo/2019.12\n",
    "        Loading requirement: intel-mkl/2019.3.199 python3/3.7.4 hdf5/1.10.5 netcdf/4.7.1\n",
    "\n",
    "```\n",
    "Note that Pangeo has its own Python installation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Step 2: Configuring your JupyterLab password on Gadi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use JupyterLab to load notebooks and monitor jobs. JupyterLab is bundled within the Pangeo environment. To setup this environment, run the following two commands:\n",
    "\n",
    "```\n",
    "$ jupyter notebook --generate-config\n",
    "$ jupyter notebook password\n",
    "```\n",
    "\n",
    "This is a stand-alone password that you will use later for accessing the JupyterLab server. You can use this command to reset your password at any time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Exiting the Pangeo environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can quit the environment at any time by running:\n",
    "```\n",
    "$pangeo.end.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submitting a multi-node Pangeo job to Raijin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First create a directory where you will run the jupyter notebook:\n",
    "\n",
    "```\n",
    "$ mkdir -p ~/pangeo/tutorial\n",
    "\n",
    "```\n",
    "You can create a shell script by copying the following commands into a script file. Let’s name this file run_ipynb_job.sh:\n",
    "\n",
    "```\n",
    "#!/bin/bash\n",
    "#PBS -N pangeo_test\n",
    "#PBS -P c25\n",
    "#PBS -q normal\n",
    "#PBS -l walltime=5:00:00\n",
    "#PBS -l ncpus=96\n",
    "#PBS -l mem=384GB\n",
    "#PBS -l jobfs=100GB\n",
    "#PBS -l storage=scratch/z00+scratch/c25+gdata/c25\n",
    "module load pangeo/2019.12\n",
    "pangeo.ini.all.sh\n",
    "sleep infinity\n",
    "```\n",
    "\n",
    "Note that for Gadi, the \"#PBS -l storage=\" flag is required which must include **all** the scratch and gdata project IDs that will be used in your codes. \n",
    "\n",
    "Additionally, jobs beyond a single node must use multiples of 48 for their ncpus request. \n",
    "\n",
    "Dask requires whole nodes so you need to have a job that requires these resources. In this example we request 2 Gadi Cascade Lake nodes with 96 CPUs and 384GB memory. For further instructions about node types on Gadi, consult the [NCI user guide](https://opus.nci.org.au/display/Help/Gadi+Job+Queues) on the specific configurations. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above jobscript will load the Pangeo module, run the initialisation script called **pangeo.ini.all.sh**, and keep the environment alive for the lifetime of the PBS job. The initialisation script will set up the dask scheduler on one node and multiple workers on all nodes.\n",
    "\n",
    "To submit the job to the queue:\n",
    "\n",
    "```\n",
    "$ qsub run_ipynb_job.sh\n",
    "\n",
    "```\n",
    "\n",
    "and take note of your job_id (which may look something like 1030967.gadi-pbs). Check the queue to see when the job is running:\n",
    "\n",
    "```\n",
    "$ qstat <job_id>\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "![3](images/pangeo_setup3_gadi.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up port forwarding to access from your desktop machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the job is running on Gadi, there will be two files that are created in your current Gadi directory: \n",
    "\n",
    "* client_cmd\n",
    "* scheduler.json\n",
    "\n",
    "The file client_cmd contains commands to forward network traffic from the defined port number of the worker node to an external client machine (i.e., your desktop) via the login node gadi.nci.org.au. \n",
    "\n",
    "Running\n",
    "```\n",
    "$ more client_cmd\n",
    "\n",
    "```\n",
    "should give an output that looks something like:\n",
    "\n",
    "```\n",
    "ssh -N -L 8388:gadi-cpu-clx-2224.gadi.nci.org.au:8388 abc123@gadi.nci.org.au\n",
    "ssh -N -L 8768:gadi-cpu-clx-2224.gadi.nci.org.au:8768 abc123@gadi.nci.org.au \n",
    "\n",
    "```\n",
    "For this example, JupyterLab uses port 8388 and dask dashboard occupies port 8768 respectively from Gadi worker node gadi-cpu-clx-2224. \n",
    "\n",
    "Note that both port numbers are randomly chosen for each job and will be different each time you run a new job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, on your remote machine (e.g., Desktop), run each of the following commands separately and enter your Gadi password if prompted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CLI_1: \n",
    "\n",
    "```\n",
    "$ ssh -N -L 8388:gadi-cpu-clx-2224.gadi.nci.org.au:8388 abc123@gadi.nci.org.au &\n",
    "\n",
    "```\n",
    "\n",
    "CLI_2: \n",
    "\n",
    "```\n",
    "$ ssh -N -L 8768:gadi-cpu-clx-2224.gadi.nci.org.au:8768 abc123@gadi.nci.org.au &\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the remote JupyterLab server from your remote desktop computer\n",
    "\n",
    "In a browser on your local desktop, type the following URL “localhost:8388” – where the port matches the details above:\n",
    "\n",
    "![6](images/pangeo_setup6_gadi.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will be prompted for your JupyterLab password that you created earlier:\n",
    "![7](images/pangeo_setup7.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once your authentication has passed, a JupyterLab interface will be launched in a few seconds.\n",
    "\n",
    "![8](images/pangeo_setup8.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing a notebook example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can drag and drop a notebook from your local machine into the JupyterLab. This file will then also appear in your working directory on Gadi:\n",
    "![9](images/pangeo_setup9.png)\n",
    "\n",
    "The screen shot above shows\n",
    "\n",
    "1. Jupyter notebook interface opened from your local computer and connecting to Gadi\n",
    "2. A directory on your local machine from where a notebook is dragged and dropped into the JupyterLab interface\n",
    "3. Gadi command window showing that the notebook appears instantly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up your Jupyter notebook to use the dask server"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**At the beginning of the notebook**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To utilise the dask server established from the PBS job, it is necessary to add and run the following cell at the beginning of your notebook: \n",
    "\n",
    "```\n",
    "from dask.distributed import Client,LocalCluster \n",
    "client = Client(scheduler_file='scheduler.json') \n",
    "print(client) \n",
    "```\n",
    "\n",
    "The output will show the configuration of the client and dask cluster. You can check that the number of cores matches what you requested in the job script. Now you could run your notebook as usual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**At the end of the jobscript**\n",
    "\n",
    "Add and run a cell as below to gracefully stop the job:\n",
    "\n",
    "```\n",
    "!pangeo.end.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap important notes\n",
    "\n",
    "Please make sure the following start and stop instructions are added at the beginning and the end of the notebook respectively.\n",
    "\n",
    "```\n",
    "# start the dask client\n",
    "client =  Client(scheduler_file='scheduler.json')\n",
    " \n",
    "# stop the pbs job.\n",
    "!pangeo.end.sh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View compute threads using Dask dashboard\n",
    "\n",
    "From your local desktop, open a new tab in the web browser and type the second port in the client_cmd file to open the Dask dashboard. This will allow you to see the dynamic resources of the processing. In your Jupyter notebook, a computationally intensive task will be recognised with a (*) at the start of a cell that is currently in execution.  In the Dask dashboard you would then see something similar to the following:\n",
    "\n",
    "```\n",
    "localhost:8768\n",
    "```\n",
    "\n",
    "![10](images/pangeo_setup10.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Jupyter notebook in a batch job\n",
    "\n",
    "Of course you don’t need to run Jupyter notebooks interactively. You can just submit them as a job."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Convert your Jupyter notebook to a Python script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "$ module load pangeo\n",
    "\n",
    "$ jupyter nbconvert --to script [YOUR_NOTEBOOK}.ipynb\n",
    "```\n",
    "\n",
    "Make sure you have added the following lines to the beginning of the Python script.\n",
    "\n",
    "```\n",
    "from dask.distributed import Client,LocalCluster \n",
    "client = Client(scheduler_file='scheduler.json') \n",
    "print(client) \n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create the job script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "#!/bin/bash \n",
    "#PBS -N pangeo_test \n",
    "#PBS -q normal\n",
    "#PBS -P c25\n",
    "#PBS -l walltime=5:00:00 \n",
    "#PBS -l ncpus=96 \n",
    "#PBS -l mem=384GB \n",
    "#PBS -l jobfs=100GB \n",
    "#PBS -l storage=scratch/c25+gdata/c25\n",
    " \n",
    "module load pangeo/2019.10 \n",
    "pangeo.ini.all.sh \n",
    " \n",
    "cd $PBS_O_WORKDIR \n",
    "python3 YOUR_PYSCRIPT_NAME.py \n",
    "pangeo.end.sh\n",
    "```\n",
    "\n",
    "Modify the parameters to suit your code and give it a name (e.g. **run_py.sh**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Submit your job script via 'qsub' command"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "$ qsub run_py.sh\n",
    "```\n",
    "\n",
    "\n",
    "Note that users need to manage all necessary modules by themselves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference\n",
    "\n",
    "- http://pangeo.io"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
